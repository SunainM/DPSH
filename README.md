


# ğŸ  Dynamic Personalized Smart Home (DPSH)

A distributed, IoT-based smart home system designed to simulate adaptive environments using MQTT, Node-RED, and MongoDB Atlas â€” deployed across AWS EC2 instances for scalability and fault tolerance.

---

## ğŸŒ Overview

**DPSH (Dynamic Personalized Smart Home)** integrates multiple simulated IoT sensors, cloud-based data processing, and real-time dashboards to create a personalized, scalable smart home environment.

Each simulated room (e.g., hallway, living room, bedrooms) streams sensor data such as temperature, light, motion, and facial recognition to an **EMQX MQTT broker** hosted on AWS.  
A controller service processes face detections, performs mood inference, and retrieves personalized environment settings from **MongoDB Atlas**.  
The **Node-RED** interface orchestrates data flow, applies decision logic, and visualizes real-time metrics through an interactive dashboard.

---

## ğŸ§© System Architecture

The system is composed of the following main components:

| Component | Description |
|------------|-------------|
| **Sensor Simulators** | Node.js scripts publishing temperature, light, motion, and face data for each room. |
| **MQTT Broker (EMQX)** | Dockerized MQTT broker hosted on AWS EC2, load-balanced via AWS NLB. |
| **Controller EC2** | Runs `faceMLSim.js` and `MoodAggregator` to process user moods and environment logic. |
| **MongoDB Atlas** | Stores user identity, mood preferences, and environmental settings. |
| **Node-RED EC2** | Subscribes to MQTT topics, applies logic flows, and drives dashboard visualization. |
| **PM2 Process Manager** | Ensures fault-tolerant Node.js process management and automatic restarts. |

---

## âš™ï¸ Features

- ğŸŒ¡ï¸ **Real-Time Sensor Simulation** â€“ Multi-room environmental data streams.
- ğŸ’¡ **Adaptive Environment Control** â€“ Lights and temperature adjust automatically based on mood.
- ğŸ§  **Face-Based Personalization** â€“ Facial recognition simulates mood-based preferences.
- â˜ï¸ **AWS Cloud Deployment** â€“ EMQX, Node-RED, and controllers deployed on EC2 behind a Network Load Balancer.
- ğŸ“Š **Node-RED Dashboard** â€“ Interactive visualization for rooms, users, and system state.
- ğŸ§© **Scalable Modular Design** â€“ Add rooms or devices by editing configuration JSON files.

---

## ğŸ—ï¸ Project Structure

```

ProjectSmartHome/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ sensors/
â”‚   â”‚   â”œâ”€â”€ sims/
â”‚   â”‚   â”‚   â”œâ”€â”€ temp.sim.js
â”‚   â”‚   â”‚   â”œâ”€â”€ motion.sim.js
â”‚   â”‚   â”‚   â”œâ”€â”€ light.sim.js
â”‚   â”‚   â”‚   â”œâ”€â”€ facecam.sim.js
â”‚   â”‚   â”œâ”€â”€ bed1.json
â”‚   â”‚   â”œâ”€â”€ bed2.json
â”‚   â”‚   â”œâ”€â”€ hallway.json
â”‚   â”‚   â””â”€â”€ living.json
â”‚   â”‚
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ faceMLSim.js
â”‚   â”‚   â”œâ”€â”€ moodAggregator.js
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚
â”‚   â””â”€â”€ .env
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ package.json
â”œâ”€â”€ README.md
â””â”€â”€ docs/
â”œâ”€â”€ Report.pdf
â””â”€â”€ images/

````

---

## ğŸš€ Deployment Steps

### 1. Clone the repository
```bash
git clone https://github.com/<your-username>/DynamicPersonalizedSmartHome.git
cd DynamicPersonalizedSmartHome
````

### 2. Install dependencies

```bash
npm install
```

### 3. Configure environment variables

Create a `.env` file with:

```bash
BROKER_URL=mqtt://<NLB-DNS>:1883
MONGO_URL=mongodb+srv://<user>:<pass>@cluster.mongodb.net/smarthome
DB_NAME=smarthome
FACE_COLL=faces
MOOD_COLL=moods
```

### 4. Run sensor simulators

```bash
pm2 start src/sensors/simRunner.js --name sensors
```

### 5. Start controller services

```bash
pm2 start src/controllers/faceMLSim.js --name faceML
pm2 start src/controllers/moodAggregator.js --name moodAgg
```

### 6. Launch Node-RED

```bash
node-red
```

Access the dashboard at:

```
http://<NodeRED-EC2-PublicDNS>:1880/ui
```

---

## ğŸ“¡ MQTT Topics

| Topic                   | Description                   |
| ----------------------- | ----------------------------- |
| `homeA/<room>/temp`     | Temperature readings          |
| `homeA/<room>/motion`   | Motion detection              |
| `homeA/<room>/light`    | Light status                  |
| `homeA/<room>/faceData` | Simulated face detection      |
| `homeA/<room>/mood/out` | Aggregated mood output        |
| `homeA/<room>/cmd`      | Control commands to actuators |

---

## ğŸ§° Technologies Used

| Layer                         | Tools            |
| ----------------------------- | ---------------- |
| **Simulation & Logic**        | Node.js, MQTT.js |
| **Messaging & Communication** | EMQX MQTT Broker |
| **Database**                  | MongoDB Atlas    |
| **Cloud Infrastructure**      | AWS EC2, AWS NLB |
| **Visualization**             | Node-RED         |
| **Process Management**        | PM2              |

---

## ğŸ§ª Testing & Validation

| Test Case          | Description                  | Result |
| ------------------ | ---------------------------- | ------ |
| Motion + Low Light | Light turns on automatically | âœ… Pass |
| Idle > 30s         | Auto light off               | âœ… Pass |
| Face Detection     | Triggers mood lookup         | âœ… Pass |
| Multi-user Mood    | Aggregation works            | âœ… Pass |
| MQTT Latency       | Under 2 seconds              | âœ… Pass |

---

## ğŸ“ˆ Scalability and Future Work

* Integrate real facial recognition models (e.g., OpenCV + TensorFlow Lite).
* Expand to real IoT devices using ESP32 / Raspberry Pi nodes.
* Add a central web dashboard for remote monitoring.
* Migrate to containerized microservices using AWS ECS or Kubernetes.

---

## ğŸ‘¤ Author

**Sunain Mushtaq**
ğŸ“š Computer Science Student â€“ Deakin University
ğŸ“§ [[your.email@example.com](mailto:your.email@example.com)]
ğŸ”— [LinkedIn](https://linkedin.com/in/your-profile)

---

## ğŸ“ License

This project is licensed under the **MIT License** â€“ feel free to modify and build upon it for educational or research purposes.


